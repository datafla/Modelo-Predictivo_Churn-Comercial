{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: 'MODELO PREDICTIVO DE CLASIFICACIÓN DE CHURN BASADO EN PATRONES DE CONTACTO PARA UNA STARTUP BOLIVIANA'  \n",
    "#### Author: Flavia Davila Perez\n",
    "#### Arquitecture: Medallion\n",
    "##### Stage: Silver \n",
    "##### Sub-Stage: Enriched\n",
    "Description: Data transformation: pivoting, merging, calculation of new columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from silver_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Filtered Data from CSV\n",
    "\n",
    "# Activities\n",
    "df_activities_com = pd.read_csv(r'..\\data\\output_silver\\02_silver_filtered\\activities_com.csv')\n",
    "df_activities_exp = pd.read_csv(r'..\\data\\output_silver\\02_silver_filtered\\activities_exp.csv')\n",
    "\n",
    "# Deals\n",
    "df_deals_com = pd.read_csv(r'..\\data\\output_silver\\02_silver_filtered\\deals_com.csv')\n",
    "df_deals_exp = pd.read_csv(r'..\\data\\output_silver\\02_silver_filtered\\deals_exp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals_com = df_deals_com[df_deals_com.duplicated(subset='org_id.value', keep=False) == False]\n",
    "df_deals_exp = df_deals_exp[df_deals_exp.duplicated(subset='org_id.value', keep=False) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column \"Fecha y Hora de vencimiento\" - COM\n",
    "df_activities_com[\"Fecha y Hora de vencimiento\"] = (\n",
    "    df_activities_com[\"Fecha de vencimiento\"].astype(str) + \" \" +\n",
    "    df_activities_com[\"Hora de vencimiento\"].astype(str)\n",
    ")\n",
    "\n",
    "# drop old columns\n",
    "df_activities_com = df_activities_com.drop(\n",
    "    [\"Fecha de vencimiento\", \"Hora de vencimiento\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column \"Fecha y Hora de vencimiento\" - EXP\n",
    "df_activities_exp[\"Fecha y Hora de vencimiento\"] = (\n",
    "    df_activities_exp[\"Fecha de vencimiento\"].astype(str) + \" \" +\n",
    "    df_activities_exp[\"Hora de vencimiento\"].astype(str)\n",
    ")\n",
    "\n",
    "# drop old columns\n",
    "df_activities_exp = df_activities_exp.drop(\n",
    "    [\"Fecha de vencimiento\", \"Hora de vencimiento\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting \"df_activities_com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining meetings done and canceled\n",
    "R1_done = [\n",
    "    'R1'\n",
    "]\n",
    "\n",
    "R2_done = [\n",
    "    'R2 online', \n",
    "    'R2 In', \n",
    "    'R2 Out'\n",
    "]\n",
    "\n",
    "R1_canceled = [\n",
    "    'R1 cancelado' \n",
    "]\n",
    "\n",
    "R2_canceled = [\n",
    "    'R2 in cancelado', \n",
    "    'R2 out cancelado',\n",
    "    'R2 online cancelado'\n",
    "]\n",
    "\n",
    "# defining calls effectives and not effectives\n",
    "\n",
    "effectives_calls = [\n",
    "    'Llamada de prospección efectiva', \n",
    "    'Llamada de seguimiento efectiva', \n",
    "]\n",
    "non_effectives_calls = [\n",
    "    'Llamada de prospección No efectiva', \n",
    "    'Llamada de seguimiento no efectiva',\n",
    "    'Llamada sin avance'\n",
    "]\n",
    "\n",
    "# defining WhatsApp activities\n",
    "wa_activities = [\n",
    "    'Seguimiento WSP',\n",
    "    'Videowsp'\n",
    "]\n",
    "\n",
    "# defining total activities in COM\n",
    "calls = effectives_calls + non_effectives_calls \n",
    "meetings_done = R1_done + R2_done\n",
    "meetings_canceled = R1_canceled + R2_canceled\n",
    "activities = calls + meetings_done + meetings_canceled + wa_activities\n",
    "\n",
    "\n",
    "# new count columns \n",
    "column_mappings = {\n",
    "    'Total Actividades': activities,\n",
    "    'Conteo Llamadas': calls,\n",
    "    'Llamadas Efectivas': effectives_calls,\n",
    "    'Llamadas No Efectivas': non_effectives_calls,\n",
    "    'Contacto WA': wa_activities,\n",
    "    'Reuniones Hechas': meetings_done,\n",
    "    'Reuniones Canceladas': meetings_canceled,\n",
    "    'Conteo R1': R1_done,\n",
    "    'Conteo R2': R2_done,\n",
    "    'Conteo R1 Canceladas' : R1_canceled,\n",
    "    'Conteo R2 Canceladas' : R2_canceled\n",
    "    }\n",
    "\n",
    "for column, activity_list in column_mappings.items():\n",
    "    df_activities_com[column] = df_activities_com['Tipo'].isin(activity_list).astype(int)\n",
    "\n",
    "# count activities \n",
    "count_per_deal = df_activities_com.groupby('Organización').agg(\n",
    "    Total_Actividades=('Tipo', 'count'),\n",
    "    Total_Llamadas=('Conteo Llamadas', 'sum'),\n",
    "    Llamadas_Efectivas=('Llamadas Efectivas', 'sum'),\n",
    "    Llamadas_No_Efectivas=('Llamadas No Efectivas', 'sum'),\n",
    "    WA_Seguimiento=('Contacto WA', 'sum'),\n",
    "    Reuniones_Hechas = ('Reuniones Hechas', 'sum'),\n",
    "    Reuniones_Canceladas = ('Reuniones Canceladas', 'sum'),\n",
    "    Reunion1_Hechas = ('Conteo R1', 'sum'),\n",
    "    Reunion2_Hechas = ('Conteo R2', 'sum'),\n",
    "    Reunion1_Canceladas = ('Conteo R1 Canceladas', 'sum'),\n",
    "    Reunion2_Canceladas = ('Conteo R2 Canceladas', 'sum')\n",
    "\n",
    ").reset_index()\n",
    "\n",
    "# extracting date for each activity\n",
    "date_activities = df_activities_com[\n",
    "    df_activities_com['Tipo'].isin(activities)\n",
    "].pivot_table(\n",
    "    index='Organización',\n",
    "    columns='Tipo',\n",
    "    values='Hora en que se marcó como completada',\n",
    "    aggfunc=lambda x: ', '.join(x) # combine all dates between commas\n",
    ").reset_index()\n",
    "\n",
    "# rename columns\n",
    "date_activities.columns.name = None\n",
    "date_activities.rename(columns=lambda x: f\"Fecha {x}\" if x != 'Organización' else x, \n",
    "                       inplace=True\n",
    "                       )\n",
    "\n",
    "# Combinar ambos resultados\n",
    "df_pivoted_com = pd.merge(\n",
    "    count_per_deal, \n",
    "    date_activities,\n",
    "    on='Organización',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting \"df_activities_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining activities done and canceled\n",
    "\n",
    "kickoff_done = [\n",
    "    'Kick Off'\n",
    "]\n",
    "\n",
    "kickoff_canceled = [\n",
    "    'Kick Off cancelada'\n",
    "]\n",
    "\n",
    "\n",
    "training_done = [\n",
    "    'Capacitación ERP'\n",
    "]\n",
    "\n",
    "training_canceled = [\n",
    "    'Capacitación ERP cancelada'\n",
    "]\n",
    "\n",
    "# defining calls effectives and non effectives\n",
    "effectives_calls = [\n",
    "    'Llamada de seguimiento efectiva'\n",
    "]\n",
    "\n",
    "non_effectives_calls = [\n",
    "    'Llamada de seguimiento no efectiva'\n",
    "]\n",
    "\n",
    "# defining WhatsApp activities\n",
    "wa_activities = [\n",
    "    'Seguimiento WSP',\n",
    "    'Videowsp'\n",
    "]\n",
    "\n",
    "# defining total activities in EXP\n",
    "calls = effectives_calls + non_effectives_calls \n",
    "kickoff_done = kickoff_done\n",
    "kickoff_canceled = kickoff_canceled\n",
    "trainings_done = training_done\n",
    "trainings_canceled = training_canceled\n",
    "activities = calls + kickoff_done + kickoff_canceled + trainings_done + trainings_canceled + wa_activities\n",
    "\n",
    "# new count columns \n",
    "column_mappings = {\n",
    "    'Total Actividades': activities,\n",
    "    'Conteo Llamadas': calls,\n",
    "    'Llamadas Efectivas': effectives_calls,\n",
    "    'Llamadas No Efectivas': non_effectives_calls,\n",
    "    'Contacto WA': wa_activities,\n",
    "    'Conteo Kick Off Hechas' : kickoff_done,\n",
    "    'Conteo Kick Off Canceladas' : kickoff_canceled,\n",
    "    'Conteo Capacitaciones Hechas': trainings_done,\n",
    "    'Conteo Capacitaciones Canceladas': trainings_canceled,\n",
    "}\n",
    "\n",
    "# Crear las nuevas columnas usando un bucle\n",
    "for column, activity_list in column_mappings.items():\n",
    "    df_activities_exp[column] = df_activities_exp['Tipo'].isin(activity_list).astype(int)\n",
    "\n",
    "\n",
    "# count activities \n",
    "count_per_deal = df_activities_exp.groupby('Organización').agg(\n",
    "    Total_Actividades=('Tipo', 'count'),\n",
    "    Total_Llamadas=('Conteo Llamadas', 'sum'),\n",
    "    Llamadas_Efectivas=('Llamadas Efectivas', 'sum'),\n",
    "    Llamadas_No_Efectivas=('Llamadas No Efectivas', 'sum'),\n",
    "    WA_Seguimiento=('Contacto WA', 'sum'),\n",
    "    Kickoff_Hechas=('Conteo Kick Off Hechas','sum'),\n",
    "    Kickoff_Canceladas=('Conteo Kick Off Canceladas', 'sum'),\n",
    "    Capacitaciones_Hechas=('Conteo Capacitaciones Hechas', 'sum'),\n",
    "    Capacitaciones_Canceladas=('Conteo Capacitaciones Canceladas', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# extracting date for each activity\n",
    "date_activities = df_activities_exp[\n",
    "    df_activities_exp['Tipo'].isin(activities)\n",
    "].pivot_table(\n",
    "    index='Organización',\n",
    "    columns='Tipo',\n",
    "    values='Hora en que se marcó como completada',\n",
    "    aggfunc=lambda x: ', '.join(x) # combine all dates between commas\n",
    ").reset_index()\n",
    "\n",
    "# rename columns\n",
    "date_activities.columns.name = None\n",
    "date_activities.rename(columns=lambda x: f\"Fecha {x}\" if x != 'Organización' else x, \n",
    "                       inplace=True\n",
    "                       )\n",
    "\n",
    "# Combinar ambos resultados\n",
    "df_pivoted_exp = pd.merge(\n",
    "    count_per_deal,\n",
    "    date_activities, \n",
    "    on='Organización', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge of deals and activities from comercial\n",
    "df_com_merged = pd.merge(df_pivoted_com, df_deals_com, \n",
    "                      left_on='Organización', \n",
    "                      right_on='org_id.value', \n",
    "                      # how='right'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge of deals and activities from comercial\n",
    "df_exp_merged = pd.merge(df_pivoted_exp, df_deals_exp, \n",
    "                      left_on='Organización', \n",
    "                      right_on='org_id.value', \n",
    "                      # how='right'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = df_com_merged.copy()\n",
    "df_exp = df_exp_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comercial Enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split grouped date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_split = [\n",
    "    ('Fecha Llamada de prospección efectiva', 'Llamada de prospección efectiva'),\n",
    "    ('Fecha Llamada de prospección No efectiva', 'Llamada de prospección no efectiva'),\n",
    "    ('Fecha Llamada de seguimiento efectiva', 'Llamada de seguimiento efectiva'),\n",
    "    ('Fecha Llamada de seguimiento no efectiva', 'Llamada de seguimiento no efectiva'),\n",
    "    ('Fecha Llamada sin avance', 'Llamada sin avance'),\n",
    "    ('Fecha Seguimiento WSP', 'Seguimiento WSP'),\n",
    "    ('Fecha Videowsp', 'Video WSP'),\n",
    "    ('Fecha R1', 'R1'), \n",
    "    ('Fecha R1 cancelado', 'R1 Cancelado'), \n",
    "    ('Fecha R2 In', 'R2 In'), \n",
    "    ('Fecha R2 Out','R2 Out'),\n",
    "    ('Fecha R2 online', 'R2 Online'),\n",
    "    ('Fecha R2 in cancelado', 'R2 In Cancelado'),\n",
    "    ('Fecha R2 out cancelado', 'R2 Out Cancelado'),\n",
    "    ('Fecha R2 online cancelado', 'R2 Online Cancelado')\n",
    "]\n",
    "\n",
    "for original_column, new_prefix in dates_to_split:\n",
    "    df_com = split_column(df_com, original_column, new_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "prefix_dates_com = [\n",
    "    'Negocio creado el', \n",
    "    'Fecha de ganado', \n",
    "    'Fecha de cierre prevista'\n",
    "]\n",
    "\n",
    "prefix_calls_com = [\n",
    "    'Llamada de prospección efectiva', \n",
    "    'Llamada de prospección no efectiva', \n",
    "    'Llamada de seguimiento efectiva', \n",
    "    'Llamada de seguimiento no efectiva', \n",
    "    'Llamada sin avance', \n",
    "    'Seguimiento WSP', \n",
    "    'Video WSP', \n",
    "]\n",
    "prefix_meetings_com = [\n",
    "    'R1', \n",
    "    'R1 Cancelado',\n",
    "    'R2'\n",
    "]\n",
    "\n",
    "prefix_com = prefix_dates_com + prefix_calls_com + prefix_meetings_com\n",
    "\n",
    "df_com = process_date_columns(df_com, prefix_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\1186315701.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Primer Contacto'] = df_com[columns].min(axis=1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\1186315701.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Tipo Primer Contacto'] = df_com.apply(contact_type, axis=1, col_name='Primer Contacto', prefix_and_cat=prefix_and_cat)\n"
     ]
    }
   ],
   "source": [
    "# finding the kind of the first contact, also the date\n",
    "prefix_and_cat = {\n",
    "    'Llamada de prospección efectiva': 'Efectiva',\n",
    "    'Llamada de prospección no efectiva': 'No Efectiva',\n",
    "    'Llamada sin avance': 'Sin Avance'\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_com.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "# Null Values to ''\n",
    "df_com[columns] = df_com[columns].fillna('')\n",
    "\n",
    "df_com['Primer Contacto'] = df_com[columns].min(axis=1)\n",
    "\n",
    "df_com['Tipo Primer Contacto'] = df_com.apply(contact_type, axis=1, col_name='Primer Contacto', prefix_and_cat=prefix_and_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\3669088385.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Primera Reunión'] = df_com[columns].min(axis=1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\3669088385.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Tipo Primera Reunión'] = df_com.apply(contact_type, axis=1, col_name='Primera Reunión', prefix_and_cat=prefix_and_cat)\n"
     ]
    }
   ],
   "source": [
    "# finding the kind of the first meeting, also the date\n",
    "prefix_and_cat = {\n",
    "    'R1': 'Hecha',\n",
    "    'R1 Cancelado': 'Cancelada'\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_com.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "# Null Values to ''\n",
    "df_com[columns] = df_com[columns].fillna('')\n",
    "\n",
    "df_com['Primera Reunión'] = df_com[columns].min(axis=1)\n",
    "\n",
    "df_com['Tipo Primera Reunión'] = df_com.apply(contact_type, axis=1, col_name='Primera Reunión', prefix_and_cat=prefix_and_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\2520629443.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Segunda Reunión'] = df_com[columns].min(axis=1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\2520629443.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Tipo Segunda Reunión'] = df_com.apply(contact_type, axis=1, col_name='Segunda Reunión', prefix_and_cat=prefix_and_cat)\n"
     ]
    }
   ],
   "source": [
    "# finding the kind of the second meeting, also the date\n",
    "prefix_and_cat = {\n",
    "    'R2 In': 'Hecha',\n",
    "    'R2 Out': 'Hecha',\n",
    "    'R2 Online' : 'Hecha',\n",
    "    'R2 In Cancelado': 'Cancelada',\n",
    "    'R2 Out Cancelado': 'Cancelada',\n",
    "    'R2 Online Cancelado': 'Cancelada'\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_com.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "# Null Values to ''\n",
    "df_com[columns] = df_com[columns].fillna('')\n",
    "\n",
    "df_com['Segunda Reunión'] = df_com[columns].min(axis=1)\n",
    "\n",
    "df_com['Tipo Segunda Reunión'] = df_com.apply(contact_type, axis=1, col_name='Segunda Reunión', prefix_and_cat=prefix_and_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\UMSS 2024\\experiencia\\notebooks\\../scripts\\silver_functions.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[end_date]-df[start_date]\n"
     ]
    }
   ],
   "source": [
    "# 'Tiempo DealCreado - Primer Contacto'\n",
    "df_com = time_calculator_min(df_com, 'Negocio creado el', 'Primer Contacto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\866244994.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['Rango de Contacto'] = np.select(\n"
     ]
    }
   ],
   "source": [
    "# 'Tiempo Negocio creado el-Primer Contacto'\n",
    "df_com['Rango de Contacto'] = np.select(\n",
    "    [\n",
    "        df_com['Tiempo Negocio creado el-Primer Contacto (min)'].eq(''),  \n",
    "        df_com['Tiempo Negocio creado el-Primer Contacto (min)'].isna(),  \n",
    "        df_com['Tiempo Negocio creado el-Primer Contacto (min)'] < 6  \n",
    "    ],\n",
    "    [\n",
    "        'Sin Llamada de primer contacto', \n",
    "        'Sin Llamada de primer contacto', \n",
    "        'Dentro del rango' \n",
    "    ],\n",
    "    default='Fuera del rango'  \n",
    ")\n",
    "\n",
    "# We take into account the 6 minutes as a limit, resulting from the previously performed contact analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Category Structural Break Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\3052524186.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['New Categories'] = np.where(\n"
     ]
    }
   ],
   "source": [
    "# New Categories\n",
    "\n",
    "date = pd.Timestamp('2024-04-01')\n",
    "\n",
    "df_com['New Categories'] = np.where(\n",
    "    df_com['Negocio creado el'] > date,  \n",
    "    1,  \n",
    "    0 \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\4004547658.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['R1'] = np.where(\n"
     ]
    }
   ],
   "source": [
    "df_com['R1'] = np.where(\n",
    "    df_com['Tipo Primera Reunión'] == 'Hecha',\n",
    "    1,  \n",
    "    0   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\1420537603.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['R2'] = np.where(\n"
     ]
    }
   ],
   "source": [
    "df_com['R2'] = np.where(\n",
    "    df_com['Tipo Segunda Reunión'] == 'Hecha',\n",
    "    1,  \n",
    "    0   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15608\\4107020047.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_com['R1yR2'] = np.where((df_com['R1'] == 1) & (df_com['R2'] == 1), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "df_com['R1yR2'] = np.where((df_com['R1'] == 1) & (df_com['R2'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_com[['R1', 'R2', 'R1yR2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R1  R2  R1yR2\n",
       "0   1   0        498\n",
       "    0   0         98\n",
       "1   1   1         70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy from df_com\n",
    "df_com_metrics = df_com.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'org_id.value',\n",
    "    'Tipo de cliente',  \n",
    "    'Total_Actividades',  \n",
    "    'Total_Llamadas', \n",
    "    'Llamadas_Efectivas', \n",
    "    'Llamadas_No_Efectivas', \n",
    "    'WA_Seguimiento',\n",
    "    'Reuniones_Hechas', \n",
    "    'Reuniones_Canceladas',     \n",
    "    'Tipo Primer Contacto',  \n",
    "    'Rango de Contacto', \n",
    "    'New Categories',\n",
    "    'R1yR2'\n",
    "    ]\n",
    "\n",
    "df_com_metrics = df_com_metrics[columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience Enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Grouped date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_split = [\n",
    "    ('Fecha Llamada de seguimiento efectiva', 'Llamada de seguimiento efectiva'),\n",
    "    ('Fecha Llamada de seguimiento no efectiva', 'Llamada de seguimiento no efectiva'),\n",
    "    ('Fecha Seguimiento WSP', 'Seguimiento WSP'),\n",
    "    ('Fecha Kick Off', 'Kick Off'), \n",
    "    ('Fecha Kick Off cancelada', 'Kick Off cancelada'), \n",
    "    ('Fecha Capacitación ERP', 'Capacitación ERP'),\n",
    "    ('Fecha Capacitación ERP cancelada', 'Capacitación ERP cancelada')\n",
    "]\n",
    "\n",
    "for original_column, new_prefix in dates_to_split:\n",
    "    df_exp = split_column(df_exp, original_column, new_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\UMSS 2024\\experiencia\\notebooks\\../scripts\\silver_functions.py:78: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# convert to datetime\n",
    "prefix_dates_exp = [\n",
    "    'Negocio creado el', \n",
    "    'Fecha de ganado', \n",
    "    'Fecha de perdido',\n",
    "    'Fecha de cierre prevista',\n",
    "    '(EXP) Fecha Kickoff', \n",
    "    '(EXP) Fecha de finalización de onboarding',\n",
    "    '(C)(EXP) Fecha Suscripción Inicio'\n",
    "]\n",
    "\n",
    "prefix_calls_exp = [\n",
    "    'Llamada de seguimiento efectiva', \n",
    "    'Llamada de seguimiento no efectiva', \n",
    "    'Seguimiento WSP', \n",
    "    'Video WSP',     \n",
    "]\n",
    "\n",
    "prefix_meetings_exp = [\n",
    "    'Kick Off',\n",
    "    'Kick Off cancelada',\n",
    "    'Capacitación ERP',\n",
    "    'Capacitación ERP cancelada'\n",
    "]\n",
    "\n",
    "prefix_exp = prefix_dates_exp + prefix_calls_exp + prefix_meetings_exp\n",
    "\n",
    "df_exp = process_date_columns(df_exp, prefix_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the kind of the first contact, also the date\n",
    "prefix_and_cat = {\n",
    "    'Llamada de seguimiento efectiva': 'Efectiva',\n",
    "    'Llamada de seguimiento no efectiva': 'No Efectiva',\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_exp.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "# Null Values to ''\n",
    "df_exp[columns] = df_exp[columns].fillna('')\n",
    "\n",
    "df_exp['Primer Seguimiento'] = df_exp[columns].min(axis=1)\n",
    "\n",
    "df_exp['Tipo Primer Seguimiento'] = df_exp.apply(contact_type, axis=1, col_name='Primer Seguimiento', prefix_and_cat=prefix_and_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting a data frame\n",
    "df_com_subset = df_com[['org_id.value', 'Fecha de ganado']]\n",
    "\n",
    "# Realizar el merge\n",
    "df_exp = df_exp.merge(df_com_subset, on='org_id.value', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting a data frame\n",
    "df_exp_subset = df_exp[['org_id.value', '(EXP) Fecha Kickoff', '(EXP) Fecha de finalización de onboarding']]\n",
    "\n",
    "# Realizar el merge\n",
    "df_exp = df_exp.merge(df_exp_subset, on='org_id.value', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp['(EXP) Fecha Kickoff_y'] = pd.to_datetime(df_exp['(EXP) Fecha Kickoff_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the kind of \n",
    "df_exp['Onboarding'] = np.where(\n",
    "    df_exp['(EXP) Fecha de finalización de onboarding_y'].isna(), \n",
    "    'No Finalizado',\n",
    "    'Finalizado'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp['(EXP) Fecha Kickoff_y'] = df_exp['(EXP) Fecha Kickoff_y'] + pd.Timedelta(hours=23, minutes=59, seconds=59)\n",
    "# aumentamos la ultima hora del dia para que al comparar no se confunda como el primero en ocurrir\n",
    "\n",
    "# finding the kind of the first training, also the date\n",
    "prefix_and_cat = {\n",
    "    '(EXP) Fecha Kickoff': 'Efectiva',\n",
    "    'Capacitación ERP': 'Cancelada',\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_exp.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "\n",
    "# Null Values to ''\n",
    "df_exp[columns] = df_exp[columns].fillna('')\n",
    "\n",
    "df_exp['Kick Off'] = df_exp[columns].min(axis=1)\n",
    "\n",
    "df_exp['Tipo Kick Off'] = df_exp.apply(contact_type, axis=1, col_name='Kick Off', prefix_and_cat=prefix_and_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the kind of the first training, also the date\n",
    "prefix_and_cat = {\n",
    "    'Capacitación ERP': 'Hecha',\n",
    "    'Capacitación ERP cancelada': 'Cancelada',\n",
    "}\n",
    "\n",
    "columns = []\n",
    "for prefix in prefix_and_cat.keys():\n",
    "    columns += [col for col in df_exp.columns if col.startswith(prefix)]\n",
    "\n",
    "columns = list(set(columns))\n",
    "\n",
    "# Null Values to ''\n",
    "df_exp[columns] = df_exp[columns].fillna('')\n",
    "\n",
    "df_exp['Primera Capacitación'] = df_exp[columns].min(axis=1)\n",
    "\n",
    "df_exp['Tipo Primera Capacitación'] = df_exp.apply(contact_type, axis=1, col_name='Primera Capacitación', prefix_and_cat=prefix_and_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Tiempo Negocio creado el - Fecha de perdido'\n",
    "df_exp = time_calculator_days(df_exp, 'Fecha de ganado_y', 'Fecha de perdido') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 539 entries, 0 to 538\n",
      "Series name: Fecha de perdido\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "169 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 4.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_exp['Fecha de perdido']. info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Tiempo Negocio creado el-Fecha de perdido (días)'\n",
    "df_exp['Churn Comercial'] = df_exp['Tiempo Fecha de ganado_y-Fecha de perdido (días)'].apply(\n",
    "    lambda x: 1 if x < 90 and pd.notna(x) else 0\n",
    ")\n",
    "\n",
    "# We take into account a limit of 90 days for it to be considered 'Commercial Churn' \n",
    "# according to parameters previously defined in tuGerente.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy from df_exp\n",
    "df_exp_metrics = df_exp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'org_id.value',\n",
    "    'Total_Actividades',\n",
    "    'Total_Llamadas',\n",
    "    'Llamadas_Efectivas',\n",
    "    'Llamadas_No_Efectivas',\n",
    "    'WA_Seguimiento',\n",
    "    'Kickoff_Hechas',\n",
    "    'Kickoff_Canceladas',\n",
    "    'Capacitaciones_Hechas',\n",
    "    'Capacitaciones_Canceladas',\n",
    "    'Tipo Primera Capacitación',\n",
    "    'Onboarding',\n",
    "    '(C) (EXP) Plazo y Pago',\n",
    "    'Churn Comercial'\n",
    "]\n",
    "\n",
    "df_exp_metrics = df_exp_metrics[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Enriched Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final merged\n",
    "df_contact_metrics = pd.merge(df_com_metrics, df_exp_metrics, \n",
    "                      on='org_id.value', \n",
    "                      suffixes=('_com', '_exp')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV - CONTACT \n",
    "df_contact_metrics.to_csv(r'..\\data\\output_silver\\03_silver_enriched\\contact_metrics.csv', index=False)\n",
    "df_com_metrics.to_csv(r'..\\data\\output_silver\\03_silver_enriched\\contact_metrics_com.csv', index=False)\n",
    "df_exp_metrics.to_csv(r'..\\data\\output_silver\\03_silver_enriched\\contact_metrics_exp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
